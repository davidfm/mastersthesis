
\chapter{State of the art in the weather data transmission}\label{chapter4}

The previous chapters we have introduced a general overview of the basics needed to understand how weather data are collected and how a weather instrument is designed to undertake its function. Even though the purpose of this thesis is to analyze the issues found in the weather data transmission and to provide an alternative to fix these problems. Nowadays, the way in which a weather instrument is transmitting the data can be classified as generic, because the methodologies used in this task have not been optimized thinking in the data implied in the process. This practice limits the possibility to acquire data without the implementation of intermediary hops in which the data is parsed and converted to a useful data format. This results in an unnecessary investment  of CPU cycles, delays in the data delivery, incompatibility between difference brand of instruments, and at the end causing the investment of more resources and effort to exchange data between organizations. This chapter analyzes the technical points that are causing this issues in the weather data transmission.

\section{The evolution of the digital interfaces in a  \\ weather instrument}

As mentioned in chapter three, the meteorology did not advance until the invention of the telegraph. The value of the weather data resides in the ability to combine it with other sources to get some conclusions to make predictions. Nevertheless, this combination involves having the possibility to transmit this data fast and far enough. The telegraph brought this possibility, and with this new chance scientists had the opportunity to understand concepts as wind flow and storm movement\cite{METO} among others. During the 19th and 20th century the industry has been developing new improvements in the instruments manufactured; all of these improvements come supported for the new methods found by the physics to measure the phenomena, and the conversion of them to digital instruments. 

In 1969 the \gls{RS232}-C standard was published; this interface has been the mainstream technology used in the weather instruments for more than thirty years; only in the last decade some updates have been introduced in the industry, migrating to new standards as ANSI/EIA/TIA-232-F\cite{RS232S}, ANSI/EIA/TIA-422-F\cite{RS422S}, ANSI/EIA/TIA-485-F\cite{RS485S} or \gls{USB}. 

As far as we can judge this slow transition in as of the digital interfaces used in a weather instrument come supported for the fact of the wide use of \gls{RS232}-C in different fields of the industry, at the same time these interfaces fit perfectly in the needs of the weather data transmission: enough bandwidth, low cost and they are an international standard. If some updates have been introduced in the industry of the weather's instruments, they come supported by the need to adapt these interfaces to the hardware ports available at the moderns computers, seldom by the requirement of more bandwidth\footnote{In some big \gls{AWS}es in which have been placed many sensors and complex instruments, exists the possibility to need a bigger bandwidth, even so this is a specific case out of the mainstream setups.}.

It is an observable fact that the industry performs some updates in the technology to make it compatible with the moderns computers despite that the is not needed in terms of data  delivery. Moreover, the new standards are offering more capabilities a part of more bandwidth, for example, technologies as \gls{USB}, bring the opportunity to plug an \gls{AWS} to a computer and have it working without previous configurations as bit-rate, parity, etc.\footnote{Interfaces based in ANSI/EIA/TIA-232-F, ANSI/EIA/TIA-422-F, ANSI/EIA/TIA-485-F require to adapt the software to certain bit-rates, flow controls and other parameters.}

These interfaces provided by the industry are generic as in other technologies, not mattering the type of data transmitted through them; a well-known process of standardization has been performed to develop these interfaces. Though does not exist any standard specifying which type of interface should provide an \gls{AWS}, the \gls{WMO} recognizes the universality of the interfaces mentioned, and establishes them as requirement for the \gls{AWS}es performing official measurements for governmental organizations\cite{GMIMO}. Based on this we assume that a protocol implemented in an \gls{AWS} must work under these technologies; because these interfaces are generic, they have not any requirement for the data transmitted, giving complete freedom to us to implement any protocol over them.

As mentioned in section \ref{3.1.2}, the bandwidth offered for the different interfaces available in a weather instrument, are offering even more bandwidth than the amount of data that an \gls{AWS}'s CPU can process. Hence, a weather instrument has not limitations (concerning bandwidth) in the data interfaces that would prevent the possibility to implement a protocol to afford the needs of the data delivery.

Based on this retrospective we assume that the digital interfaces provided by the industry are well know and tested standards, providing mechanisms to achieve the goal of the data transmission. However, as it is explained in section \ref{4.2} no weather data transmission protocol has been defined for them. We identified this as \textbf{the first deficiency in the weather data transmission because of the potential offered by these digital interfaces is not used in the weather instruments}. 

\section{The absence of a protocol}\label{4.2}

The goal of the \gls{IETF}\cite{IETF} is to make the Internet work better. One of its multiple task implies to take care about the standardization process of the new Internet standards. A protocol is considered as standard when the IETF publishes a memorandum\footnote{This memorandums are named as \gls{RFC} for historical reasons.}, specifying all the aspects of the protocol and assigning a number in the STD series of it\cite{rfc2026}.

A research performed by the author in the \gls{RFC}s available at \gls{IETF}'s website \cite{IETF}\footnote{The searched has been performed over all the content of the RFC published: ftp://ftp.rfc-editor.org/in-notes/tar/RFC-all.tar.gz . Retrieved: 28-03-2011.}, looking for the following terms: "weather", "meteorology", "weather station", "atmosphere", "weather data", gave as result the following number of mentions. Only \textbf{9} \gls{RFC}s do direct or indirect mention to the weather data. 

The first \gls{RFC} mentioning a protocol related with the weather data is the RFC 765 \cite{rfc765} File Transfer Protocol (FTP): 

\emph{3.4.2.  BLOCK MODE
         The file is transmitted as a series of data blocks preceded by
         one or more header bytes.  The header bytes contain a count
         field, and descriptor code.  The count field indicates the
         total length of the data block in bytes, thus marking the
         beginning of the next data block (there are no filler bits).
         The descriptor code defines:  last block in the file (EOF) last
         block in the record (EOR), restart marker (see the Section on
         Error Recovery and Restart) or suspect data (i.e., the data
         being transferred is suspected of errors and is not reliable).
         This last code is NOT intended for error control within FTP.
         It is motivated by the desire of sites exchanging certain types
         of data (e.g., seismic or \textbf{weather data}) to send and receive all
         the data despite local errors (such as "magnetic tape read
         errors"), but to indicate in the transmission that certain
         portions are suspect).  Record structures are allowed in this
         mode, and any representation type may be used.}

Nevertheless, this reference of weather data is just an example (as the other references) that disappeared in later updates of the \gls{FTP}. 

The industry has focused its effort in improving the measure methodologies, the robustness of the instruments or other features as power consumption or life-time. Thus, the methodologies utilized to transmit weather data have been developed independently by the vendors, choosing their own data formats and techniques.

Nevertheless, the \gls{WMO} initialized different programs as \gls{GOS}, \gls{GTS} , \gls{GDPFS} \cite{WMO} among others, in which the weather data exchange is a key-component of the systems to archive the goals of these programs. In addition, as mentioned in the section \ref{3.2.2} the \gls{WMO} started a process of standardization 9 years ago.

Even assuming that the industry focused its attention on prioritizing measurements methods and product quality, the technologies related to the weather data transmission are outdated. The proof of this is that only a few governmental organizations have access to real-time information \footnote{All of these instruments are generating by default real-time data.} collected from the \gls{AWS}es\footnote{Note that these organizations can have this capability due to they invest a big effort in to develop custom systems for their weather instrument's setup.}, at the same time programs as \gls{CWOP} still depend of technologies such as \gls{FTP} or \gls{APRS}, that they do not contemplate scenarios in which scalability, data on demand or real-time data is needed.  Finally, as a real example, the SMEAR project\cite{SMEAR} is experimenting the issues of not having a standard protocol for the \gls{AWS}, producing as result the implementation of intermediary points to parse and normalize the data, incompatibility between different sources of data from the same phenomenon collected with different instruments and scalability of the system among others.

Based in these facts, we can say that during the last 40 years the industry unattended the communication's side of the \gls{AWS}, adapting the instruments to be capable to use protocols as \gls{FTP} to transmit the data from the \gls{AWS} to the collection point; focalizing the effort transmiting the data not mattering at all the technologies used or if they are or not optimized for that purpose. This practice gave as result multiple data formats implemented by the vendors without any common agreement, creating a huge incompatibility between the instruments and several bottlenecks in the data transmissions. 

The following subsections expose some data format used by the vendors to archive the data transmission and analyze why these data formats are causing bottlenecks.

\subsubsection{Data formats used by the vendors}

As mentioned in previous chapters, the format in which the data is produced by \gls{AWS} is formatted is up to the vendors. Nowadays the only standards used or involved in this process is \gls{ASCII} as character-encoding scheme or \gls{NMEA-0183}. Depending on the digital interface different control characters can be used, for instance is a common practice to generate one line of data follow by the carriage return (CR) or carriage return followed by line feed (CR+LF)\footnote{CR hexadecimal value: 0x0D. LF hexadecimal value: 0x0A. CR+LF: hexadecimal value 0x0D 0x0A.}.

\begin{table}[hc]
\centering

    \begin{tabular}{ | l | l | l | l |}
    \hline    
>"BARDATA"<LF>\\
<<LF><CR>"OK"<LF><CR>\\
<"BAR 29775"<LF><CR>\\
<"ELEVATION 27"<LF><CR>\\ 
<"DEW POINT 56"<LF><CR>\\ 
<"VIRTUAL TEMP 63"<LF><CR> \\
<"C 29"<LF><CR> <"R 1001"<LF><CR>\\
<"BARCAL 0"<LF><CR> <"GAIN 1533"<LF><CR> \\
<"OFFSET 18110"<LF><CR>\\
\hline
\end{tabular}
\caption{Example of data format used in a specific AWS to communicate the barometric pressure.}
\end{table}

Depending the \gls{AWS}'s brand the data's format is completely different from other brands and vendors. In most of the cases the data format is implemented based in the vendor's wishes. These wishes can be supported by technical reasons or not. Some vendors used acronyms to refer the data values returned by the sensors, others use the whole word to refer the phenomenon; not mattering the technique used in the data format, is a fact that they do not exist any compatibility of formats between vendors.

\begin{table}[hc]
\centering
\begin{tabular}{ | l | l | l | l |}
\hline    
0r2,Ta=10.6C,Tp=10.8C,Ua=74.6P,Pa=1006.0HKHK\\
\hline
\end{tabular}
\caption{Another example of data format used in a specific \protect \gls{AWS} to communicate different data as temperature or barometric pressure.}
\end{table}

A part of these big differences between the formats used in the digital interfaces, is needed to highlight that also the field's value used in \gls{CSV} or \gls{TSV} files producted by the \gls{AWS} are unique and incompatible between vendors. Thus, two levels of incompatibility exist, first the original data is delivered in a custom formatted untill the software's side. In the software's side this data is converted to a \gls{CSV} or \gls{TSV} format with the custom fields chosen by the vendors; this causes that even having the final data in a standard format as \gls{CSV} or \gls{TSV}, the order of the fields and their denomination will be different, forcing to the scientist to add an extra layer to the workflow to normalize this data and make it ready to be combined.

\subsubsection{Data formats used by governmental organizations}

Despite the fact that vendors used privative and non standard formats for the data, the \gls{WMO} has defined some specific data representation for certain users. An example of this is the \gls{METAR} format. Approved by the \gls{ICAO}, this format is the only one considered as official to communicate weather forecasting to the aviation and at the same it is widely use for other purposes as general weather forecasting.

\begin{table}[H]
\centering
\begin{tabular}{ | l | l | l | l |}
\hline
\textbf{Phenomenon} & \textbf{METAR's acronym} \\ \hline
cumulonimbus clouds & CB\\ \hline
thunderstorm & TS\\ \hline
moderate or severe turbulence & MOD TURB, SEV TURB\\ \hline
wind shear & WS\\ \hline
hail & GR \\ \hline
\end{tabular}
\caption{Some acronyms used in METAR format \cite{METAR}.}
\end{table}

However, this format has not relationship with the formats used by the vendors. Only a few \gls{AWS}es have the ability to product the \gls{METAR} format by default. The \gls{AWS} doing this are only focus in product data useful for the aviation, wasting the opportunity to provide the data in other formats for different use.

\begin{figure}[H]
\centerline{\includegraphics[width=1\textwidth]{images/c4f4.png}}
\caption{Weather data workflow, normal AWS VS METAR's AWS.}
\end{figure}

\gls{METAR} format is just an example of the multiple data formats invented for a specific purpose. The point to highlight is that often the weather data can be represented in a complete different format compare with the original format used for it. Nevertheless, the optimization of the data format until the point in which it is transformed marks a big difference in terms of data manipulation.

With the current technology the weather data arrives in different formats and with difference times frequencies, forcing to implement customized and particular mechanisms to transform this data to the format required. The complexity of this task resides in the requirement de facto requested by the \gls{AWS}es: they need intermediary points to convert the data because by default the data provided is useless for the required result.

In conclusion, it does not matter if the vendors provide a well known documented data format of their instruments. Because the observation of the weather is performed with different instruments, the data must be normalized to make it understandable.
Thus, at the end of the data workflow (when we take data from different sources and instruments), an intermediary layer to translate the vendor's data format to a common format is required.

\subsubsection{Mainstream architecture used for the weather data transmission}

To understand where are located the bottlenecks in the weather data transmissions is needed to understand the current architecture used by the vendors to archive this goal. As explained in section \ref{3.1.2}, an \gls{AWS} is an embedded system collecting information produced by the sensors attached to it. As embedded system, it has small capabilities to perform big CPU calculations, massive data storage or data delivery, however moderns systems are pretty balanced in terms of hardware and software to archive this goal. Although the \gls{AWS} have been optimized to collect and delivery the data, the protocols used for it are generic an non-specific. As explained in previous chapters the quality of the weather predictions reside in the ability to collect and process the atmosphere data with efficiency, reliability and fast delivery.

Despite of this, the methodologies for network communications are not optimized for this purpose. The following figure shows how the data is delivery.

\begin{figure}[h!]
\centerline{\includegraphics[width=1\textwidth]{images/c4f1.png}}
\caption{Example of an \protect \gls{AWS} transmitting weather data.}
\label{f4.2}
\end{figure}

In the figure \ref{f4.2} we can appreciate an example of the methodology used to transmit the weather data. In the hardware's level the data is delivered through a digital interface as explained in section \ref{3.1.2}, using some custom vendor's data format, commonly based in abbreviations as "Tmp (Temperature)", "Bp (Barometric Pressure )" "Ws (Wind Speed)", among others. These abbreviations are understood by the software. Depending of the AWS's setup this process can happen all together between the AWS and the datalogger:

\begin{figure}[h]
\centerline{\includegraphics[width=1\textwidth]{images/c4f2.png}}
\caption{Example of a \protect \gls{AWS} and a datalogger transmitting weather data.}
\end{figure}

If the \gls{AWS} / datalogger has not network capabilities, a third entity can enter in the workflow. This entity is commonly a modern computer with the peripheral devices needed to interact with the \gls{AWS}. The computer takes the role of the weather data transmission, due to the possibilities that it offers, one computer can manage several \gls{AWS}es at the same time. Nevertheless, it does not introduce new protocols to send the data, it stills using protocols as \gls{FTP} or in some setups just shared folders using \gls{SMB}:


\begin{figure}[h!]
\centerline{\includegraphics[width=1\textwidth]{images/c4f3.png}}
\caption{Workstation taking the role of the weather data transmission.}
\end{figure}


\subsubsection{FTP, the mainstream protocol in the weather data transmission}

Disregarding the setup used to send the data to the collection point, the protocol used will be generic and in most of the cases based in \gls{FTP}. Although \gls{FTP} has the capability to operate under stream mode \cite{rfc959}, the author could not find any vendor offering the capability to deliver the data through stream \gls{FTP} connections. Even being this possible, it will involve to use the image mode (commonly known as binary mode, thus, involving byte ordering choices) to transmit the data, however this choice will subject the data transmission to problems with the endianness\footnote{\emph{"Endianness describes how multi-byte data is represented by a computer system and is dictated by the CPU architecture of the system. Unfortunately not all computer systems are designed with the same Endian- architecture. The difference in Endian-architecture is an issue when software or data is shared between computer systems. An analysis of the computer system and its interfaces will determine the requirements of the Endian implementation of the software."\cite{endianness}}.}.

This setup can fill the requirements to delivery weather data collected over different time frequencies, however, it can not offer real-time capabilities, because the \gls{FTP} is not designed for this purpose. The author identifies \textbf{the use of FTP as a deficiency in the weather data transmission} \footnote{All the \gls{AWS} checked by the author are offering the data delivery based in \gls{ASCII} files using the \gls{FTP} \gls{ASCII} mode and sending the data using the \gls{FTP} block mode. Though is possible to find some \gls{AWS} using different methodologies as \gls{HTTP} get methods or email delivery, the FTP choice is mainstream overall the industry.}, the reasons for this are based in the fact that the protocol is designed to provide network capabilities to delivery data streams based in files. Notwithstanding, the \gls{AWS}es are producing data streams based in real-time data; \textbf{the use of FTP involves an intermediary step to convert these data streams to files, to continue after this sending theses these files to the collection point}. Even though to track this data in files is needed for storage and backup reasons, the data streams  generated in real-time by the \gls{AWS} are not used at all to send them directly to the collection point. In addition, the use of this methodology is forcing extra \gls{IO} operations required by the \gls{FTP}, that are not required in other protocols in which the data transfer does not involve the use of files.

Thus, it is not available any protocol taking advantage of all the capabilities offered by the \gls{AWS}es and its sensors, instead generic protocols as \gls{FTP}  or \gls{SMB} have been chosen to transmit data. These protocols are widely and accepted as the mainstream solutions for data transmission available on the weather instruments. 

\section{The missing standard}\label{missingstd}

One of the important factors of an implemented protocol, is to know how is going to be represented the data transmitted at the end of the transmission. This helps to design the best representation required by the data; for instance a protocol implementing real-time capabilities should be focus in fast data delivery and data integrity, among others.

In addition, to know the final representation of the data helps to implement a protocol optimized for the data that is transporting, this gives as result a better software for the protocol, besides it provides the capability to implement different protocols giving the same data result\footnote{A good example of this are the peer to peer networks, in which the protocol's designers know that at end of the process the data must be a file.}. 

Nevertheless, the weather data has certain particularities; the \gls{WMO} defines a set of methods to perform different measurements, notwithstanding theses methods are changing based in the advance of the physics, and these changes are causing an instability concerning what is the best way to measure a phenomenon, thus the data representation can get affected easily. Furthermore, the correlation between phenomena generates certain scenarios in which the data results can change completely if a new method is found to measure the phenomenon. This fact determines to which point we can have or not standards for these particular data. The \gls{WMO} defines which system of units must be used to represent the data for scientific purposes, in addition several guidelines are provided by the \gls{WMO} to perform the measurements under standard procedures. However, these guidelines are not enough to specify the final format of the data.

The \gls{WMO} started a process of standardization in \textbf{2002}, the goal is to create a data format to fit the requirements of the \gls{GOS}, in other words to provide a common basement to represent the data of the weather's observations. This is an arduous task, not only for the amount of data that is needed to manage, also for the big a mount of different phenomena in the atmosphere that are producing different data and their particularities. It is expected that in some point, the \gls{WMO} will publish a standard for weather's metadata representation, nevertheless, after 9 years this process still under development.

The absence of a standard for weather data representation is one of the key-issues of the current situation. Without knowing how must be formatted the data at the end of the collection workflow, is understandable that vendors ended implementing their own formats without compatibility. 

This is an open issue that unfortunately can not be treated in this thesis. The author recognizes that the implementation of a protocol to transmit the weather data without to know the final format of the data is a risky but an interesting feature. In chapter eight, an exposition of the solution chose (a software library to normalize the data) is explained.

\textbf{We identify the absence of a common format for data representation as one of the major technical deficiencies in the weather data transmission}. In addition, the absence of a common data format in the collection point as well, forces to convert the weather data multiple times to the final format. OpenWeather considers this issue and provides some mechanisms to implement smoothly and mostly transparent the conversion from OpenWeather's format to a future data standard.

\section{Data transmission and Automatic \\ Weather Stations}

As embedded systems the \gls{AWS} have more limitations that moderns computers, not having capabilities to perform complex \gls{CPU} operations or to manipulate a considerable amount of data. Most of the modern \gls{AWS}es offer the possibility to interact with them in a small scale. Commonly, this interact is focused in three tasks:

\begin{itemize}
\item AWS configuration
\item Sensor's calibration
\item Data retrieval
\end{itemize}

Even so in most of the cases the \gls{AWS}es behave as "broadcasters" of weather data. The tasks of configuration and sensor's calibration are performed only a few times in the instrument, happening this at the beginning of the \gls{AWS}'s installation and in some periodical calibrations during the life-time of the instrument; both operations are performed in most of the cases through command's line parameters or some \gls{GUI} developed for this purposed. As it was explained in section \ref{3.2.2}, the data transmission with an \gls{AWS} is performed through digital interfaces based in serial communications standards, it means that at the end all the data transmitted and received in an \gls{AWS} goes through some data format implemented by the vendor that provides a set of custom instructions. 

\begin{table}[hc]
\centering
\begin{tabular}{ | l | l | l | l |}
\hline    
>"BAUD 9600"<LF> \\
<<LF><CR>"OK"<LF><CR>\\
\hline
\end{tabular}
\caption{Example of command configuring the baud rate of the digital interface in an \protect \gls{AWS}.}
\end{table}

Even if this practice is something understandable\footnote{The author recognize that to have a proprietary set of instructions can be a method to keep some industrial's secret of the instruments, however this practice difficulties the implementation of standard methodologies to interact with multiple the instrument.}, an exception should be made in the data retrieval operation.

Most of the \gls{AWS}es offer the possibility to retrieve particular data if a specific command is sent to them. Again the method to obtain this data is up to the vendor, not being compatible these instructions between vendors, and even sometimes even not between the products of the same manufacturer.

The mechanisms to retrieve data from the \gls{AWS}es \textbf{are critical} in order to implement a protocol with real-time capabilities. We need to differentiate  two use cases on an \gls{AWS}. The first use case involves the data broadcasting that the \gls{AWS} is performing by default if it is configured as "automatic mode"\footnote{This is the default configuration used in almost all the scenarios.}. The \gls{AWS} just send the data through the digital interface in the time frequency configured, for this case is not required interaction with the \gls{AWS}; to read the data from the digital interface is enough to use it in the protocol. Nevertheless the second use case involves the retrieval of particular data. One example of this is a user interested in to know the average of temperature recorded by the \gls{AWS} in the last week. This data is not sent by default because it is not part of the information collected in real-time for the \gls{AWS}, to get the data the user must send a command asking for it to the \gls{AWS}:

\begin{table}[hc]
\centering
\begin{tabular}{ | l | l | l | l |}
\hline    
\textbf{Command}:  aR2<cr><lf> \\
\textbf{Response}: 0R2,Ta=23.6C,Ua=14.2P,Pa=1026.6H<cr><lf>\\
\hline
\end{tabular}
\caption{Example of command asking for \protect \gls{PTH} data.}
\end{table}

This second use case introduces much more complexity. If a particular data not send by default is needed, the interaction with the \gls{AWS} is mandatory, however, to interact with it implies to do it using the methodology specify by the vendor. To implement a protocol that takes this use case in consideration involves to implement a command-translator between the \gls{AWS} and the protocol implementation. \textbf{We identify this issue as another technical deficiency in the weather transmission in order to enable the capability to retrieve specific data on demand.}
\section{Summary}

In this chapter we described the state of art in the weather data transmission. We have been analyzing the different interfaces available in an \gls{AWS}, focusing on their bandwidth, and based in the bit-rate that they offer, concluding that the \gls{AWS} are not taking advantages of all the capabilities offered by the digital interfaces. This fact is enough reason to claim that the \gls{AWS}es are capable to manage more amount of data that the current quantities that they do.

Data formats used by the vendors and data format requested for the governmental organizations have been compared; finding that is not any relation between the original format used in the \gls{AWS}s and the final format in which the weather data is represented, being this one of the reasons that forces the implementation of intermediary points to translate the data to different data formats.

The absence of a protocol dedicated to the weather data transmission has been studied; the use of the \gls{FTP} has been explained and the limitations that it can involve to transmit data in real-time have been analyzed. We conclude that  \gls{FTP} is chose by the industry as non-optimal solution that fix partially the issue of the weather data transmission. In addition, the key issues of \gls{FTP} has been exposed in order to implement a system that use this protocol to delivery data in real-time.

We analyzed the implications of a missing standard to represent the weather data, concluding that without a consensus of the international community about how the weather data  should be represented, is really complex to implement a protocol to fit all the requirements needed.

Despite the absence of a protocol and the use of multiple protocols and data formats, the industry and weather organizations are using these methodologies to acquire weather data in their weather data networks.  Although projects such as \gls{GOS} or \gls{GDPFS},  are looking for technologies to optimize and standardize the weather data transmission, the current status of weather data acquisition is based on the methodologies that the industry provided without previous agreement. These methodologies have been accepted by the weather organizations as the standards for the weather data transmission, achieving until today their purpose.

At the end of the chapter we exposed how to retrieve particular data from the \gls{AWS} involves user interaction, adding complexity to the data workflow and requiring an intermediary step to translate the data requests to the native format used in the \gls{AWS} to retrieve the data. We identify this as an impediment in order to implement a protocol that provides data on demand.

The next chapter explains in which consists OpenWeather, its architecture and how it can fix the issues explained in this chapter.
\pagebreak
